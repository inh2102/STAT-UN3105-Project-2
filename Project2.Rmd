---
title: "Project 2"
author: "Isaac Horwitz (inh2102)"
date: "10/31/2020"
output: pdf_document
urlcolor: blue
---

```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = '~/inh2102_project2')
```

NOTE: The code to replicate this project is [here](https://github.com/inh2102/STAT-UN3105-Project-2) on GitHub.

# Introduction

The goal of this project is to use an individual's (in this case, Wayne's) raw GPS data from a mobile phone and use it to predict location at a time in a future week--ultimately in an attempt to "assassinate" them. This report will operate on the assumption that the best time and place at which to bomb the individual is the data point we can predict most "reliably"--that is, one that our final model can predict with the highest accuracy, or the lowest deviation between our model and where Wayne will be. Since we don't yet have the data where Wayne will be in the future, we will test our model against past data in order to model our best guess, and select times and locations that perform the best. 

Important points that this report will examine and attempt to address are: 

- uncertainty or inaccuracies in the raw data given (the GPS giving biased estimates for longitude or latitude, giving incorrect data about times or timezones, etc.)
- the assumptions of the model this report will create, and the degree of uncertainty associated with those predictions. The final model will be highly imperfect, but represents a best guess.

# Importing and Cleaning the Raw Data

Even though the most important data is longitude, latitude, and timestamp, I keep the miscellaneous variables altitude, accuracy, bearing, and speed in case they will be useful later.

```{r, warning=FALSE,message=FALSE}
library(jsonlite)
library(tidyverse)
library(lubridate)
library(sp)
library(dlm)
library(mgcv)

df <- data.frame()
for (i in list.files("gps")) {
  setwd("~/inh2102_project2/gps")
  dat <- read_json(i,flatten=TRUE)
  time <- c()
  time_long <- c()
  accuracy <- c()
  altitude <- c()
  bearing <- c()
  speed <- c()
  longitude <- c()
  latitude <- c()
  for (i in dat[['features']]) {
    time <- c(time,i$properties[1])
    time_long <- c(time_long,i$properties[3])
    accuracy <- c(accuracy,i$properties[4])
    altitude <- c(altitude,i$properties[5])
    bearing <- c(bearing,i$properties[6])
    speed <- c(speed,i$properties[7])
    longitude <- c(longitude,i$geometry[[2]][1])
    latitude <- c(latitude,i$geometry[[2]][2])
  }
  altitude[sapply(altitude, is.null)] <- NA
  bearing[sapply(bearing, is.null)] <- NA
  speed[sapply(speed, is.null)] <- NA
  
  df <- bind_rows(df,tibble(time=unlist(time),time_long=unlist(time_long),
                  accuracy=unlist(accuracy),altitude=unlist(altitude),
                  bearing=unlist(bearing),
                speed=unlist(speed),longitude=unlist(longitude),
               latitude=unlist(latitude))) %>% tibble()
}
```

The following code chunk does two things: cleans the timestamp using the Lubridate R package to make it more easily understandable in a regression and visualization context; and creates a "SpatialPointsDataFrame" with "projected" coordinates so that our geographic data can be manipulated to calculate based on meters. 

```{r}
df$time <- paste0(substr(df$time,1,10)," ",substr(df$time,12,23))
df$time <- as.POSIXct(df$time, "%Y-%m-%d %H:%M:%S",tz="GMT")
df$day <- lubridate::day(df$time)
df$hour <- lubridate::hour(df$time)

spat_df <- SpatialPointsDataFrame(coords = df[, c("longitude", "latitude")],
                             data = df["time"],
                             proj4string=CRS("+proj=longlat +datum=WGS84")) 
spat_df@data <- spat_df@data %>% 
  mutate(time_long=df$time_long,accuracy=df$accuracy,altitude=df$altitude,
         bearing=df$bearing,speed=df$speed,day=df$day,hour=df$hour) %>%
  mutate(longitude=spat_df@coords[,1],latitude=spat_df@coords[,2])
spat_df <- spTransform(spat_df,CRSobj = "+proj=utm +zone=12 +datum=WGS84")
```

This is what the raw data looks like, with longitude on the X axis, latitude on the Y axis, and colors according to each day for which the raw data is labeled (assuming the default timezone GMT).

```{r}
plot(spat_df$longitude,spat_df$latitude,col=factor(spat_df$day))
```

Without even viewing each day individually, we can see that one day's projected coordinates are much different from each other day's -- the one indicated in black-outlined points. 

```{r, echo=FALSE, include=FALSE}
coordinates <- coordinates(spat_df)
plot(coordinates)
```

In order to visualize the data day-by-day and note any preliminary observations, I split the data by day and visualize. 

```{r}
par(mfrow=c(2,6))
for (i in split(spat_df,spat_df$day)) {
  plot(i$longitude,i$latitude,main=i$day[!duplicated(i$day)],type='b')
}
```

Here are some preliminary thoughts:

- Some of the days have more data points than others. Aug. 18 only has 90 data points, and thus appears much more sparse than the other days -- for example, the maximum is 712 data points on day Aug 27.
- The path for each day is roughly the same -- meaning we don't have to deal with expressing probabilities for where Wayne will go or where he will leave from. The origin and destination is constant.
- We will certainly have to deal with the problem of data inaccuracies, including suspected missing data (for example, that is evident on Aug. 22), as well as extra junk data we'll look at more closely on Aug. 31.

# Exploring Trends

Before building a predictive model, one interesting thing to explore is whether trends that are not present in the raw data influence the patterns in the data itself. First, we import pre-cleaned data from [Weather Underground](https://www.wunderground.com/hourly/us/mt/missoula/59801) and extract Missoula, MT hourly Farenheit temperature values for the timestamps given.

```{r}
mt_weather <- readxl::read_excel("mt_weather.xlsx")
mt_weather <- mt_weather %>% mutate(temperature = as.numeric(substr(temperature,1,3)))
```

Since the temperature data is only hourly (while the GPS data is much more granular), we standardize both datasets so that they each contain a column with the day-hour indication, and join the two dataframes in a new one called "time" so that we can visualize temperature over the time period for the data:

```{r}
mt_weather$time <- format(mt_weather$time,"%D-%H")
df_time <- df %>% mutate(time = format(time,"%D-%H"))
time <- left_join(df_time,mt_weather,by='time') %>%
  mutate(time = lubridate::parse_date_time(time,orders='mdyh'))
ggplot(time,aes(x=time,y=temperature)) + 
  geom_point() +
  geom_smooth()
```

Using a locally fitted smoother (with grey bands representing SE, or uncertainty), we can see that there are fluctuations in temperature over the time period -- it rises (during the morning) and drops at night, but over the entire time period, it goes down (as Montana transitions out of the summer).

We can also quickly visualize whether there is an association between the given "speed" data (much of which is NA) and the temperature data: 

```{r, warning=FALSE}
ggplot(time,aes(x=temperature,y=speed)) + 
  geom_point() + 
  geom_smooth(method='lm')
speed_lm <- lm(data=time,speed~temperature)
summary(speed_lm)
```

Note: as the speed data given is likely flawed, we will not here attempt to create a perfect regression model and control for the model performing better at certain values. Regardless, we can see that there is on average a modest but likely significant relationship between speed and temperature -- and on average, speed decreases by 0.03 units (possibly m/s, but not given in the data) for each increase in Farenheit temperature.

It's probably worthwhile calculating our own speed given the coordinates and timestamps, but first we need to understand some properties of the data, including how frequent each data point is, and how the data can be divided into periods of collection and non-collection (stationary, or lack of movement by Wayne).

The following code chunk examines the amount of time between each (chronologically sorted) data point to get a sense of collection frequency:

```{r sessions}
diff_df <- df %>% arrange(-desc(time))
diff <- c()
for (i in 1:length(df$time)) {
  diff[i] = difftime(df$time[i], df$time[i-1], units="secs")
}
diff <- diff[!is.na(diff)]
summary(diff)
session_indices <- which(diff>=120)
spat_df$diff[2:nrow(spat_df)] <- diff
```

The median number of seconds between each observation is 8, although there are some extreme values -- for example, a maximum of 240,381 seconds. We can define each "session" of activity somewhat arbitrarily as points for which there are fewer than 120 seconds between each data point, meaning a session ends when data is not collected for 2 minutes or more. 

```{r}
table(diff) %>% sort(decreasing=T) %>% head() %>% prop.table() 
```

Again, this tells us that the data is very noisy and imperfect -- and thus we can't take timestamps for granted whatsoever -- but that it seems the intended interval of data collection is every 8 seconds.

```{r}
plot(df$time,spat_df$longitude,col=df$day)
abline(v=df$time[session_indices],col="red")
```
The plot above presents each day in a different color, and each red line indicates the beginning of a "session." We can begin to notice that a session begins when Wayne leaves his home and ends when he is at work, and then another session begins when he leaves work for home. This is true for all data except two days: **Aug. 26** and **Aug. 31**, both of which have multiple sessions due to extraneous or missing data. 

```{r}
aug31 <- spat_df[df$time>"2020-08-31 00:00:00 GMT",]
plot(aug31$time,aug31$longitude)
abline(v=aug31$time[aug31$diff>120],col="red")
```

Aug. 31 has extra data when Wayne is stationary (at work), so we need to move this since we're prohibited from bombing him when he's sheltered.

```{r}
df <- df[-c(5352:5528),]
spat_df <- spat_df[-c(5352:5528),]
time <- time[-c(5352:5528),]
aug31 <- spat_df[spat_df$time>"2020-08-31 00:00:00 GMT",]
plot(aug31$time,aug31$longitude)
abline(v=aug31$time[aug31$diff>120],col="red")
```

```{r}
aug26 <- spat_df[spat_df$time>"2020-08-26 00:00:00 GMT"&spat_df$time<"2020-08-27 00:00:00 GMT",]
plot(aug26$time,aug26$longitude)
abline(v=aug26$time[aug26$diff>120],col="red")
```

Aug. 26 contains data where Wayne goes somewhere in the complete opposition direction of his work or home -- and thus including this data will bias all of our estimates when we have no reason to suspect he will re-visit this location. We remove these data points/this session altogether:

```{r}
df <- df[-c(3534:3620),]
spat_df <- spat_df[-c(3534:3620),]
time <- time[-c(3534:3620),]
aug26 <- spat_df[spat_df$time>"2020-08-26 00:00:00 GMT"&spat_df$time<"2020-08-27 00:00:00 GMT",]
plot(aug26$time,aug26$longitude)
abline(v=aug26$time[aug26$diff>120],col="red")
```
For visualization purposes, I hand-code each session as either 0 (home location to work location) or 1 (work location to home location).

```{r}
spat_df$session <- rep(NA,nrow(spat_df@data))
spat_df$session[1:80] <- 0
spat_df$session[81:90] <- 1
spat_df$session[91:213] <- 0
spat_df$session[214:339] <- 1
spat_df$session[340:564] <- 0
spat_df$session[565:693] <- 1
spat_df$session[694:1021] <- 0
spat_df$session[1022:1360] <- 1
spat_df$session[1361:1722] <- 0
spat_df$session[1723:2044] <- 1
spat_df$session[2045:2403] <- 0
spat_df$session[2404:2755] <- 1
spat_df$session[2756:3117] <- 0
spat_df$session[3118:3533] <- 1
spat_df$session[3534:3896] <- 0
spat_df$session[3897:4245] <- 1
spat_df$session[4246:4512] <- 0
spat_df$session[4513:4573] <- 1
spat_df$session[4574:4903] <- 0
spat_df$session[4904:5264] <- 1
spat_df$session[5265:5593] <- 0

plot(spat_df[spat_df$session==0,]$longitude,spat_df[spat_df$session==0,]$latitude,col='blue')
points(spat_df[spat_df$session==1,]$longitude,spat_df[spat_df$session==1,]$latitude,col='red')
```

In blue are the data points for the commute to work, and mirroring them are the red data points representing travel from work to home.

Having examined the period between individual data points, defined "sessions" of activity, and removed sessions containing unwanted data, we can now get a better picture of the speed between the data points we're interested in. For this, we'll construct a DLM (dynamic linear model) -- also known as a "Kalman filter," which uses uses what we know about our longitudinal data to create model our data by leveraging information we know about its uncertainties -- even produced a "smoothed" version that attempts to refine estimates.

```{r}
td <- as.numeric(diff(df$time), units="secs")
gps_variance <- 20^2
v_mat <-diag(c(gps_variance, gps_variance))
f_mat <-matrix(c(1,0,0,0, 0,1,0,0), nrow=2, byrow = TRUE)
dt <- median(td)
g_mat <-matrix(c(1, 0, dt, 0,0, 1, 0, dt,0, 0, 1, 0,0, 0, 0, 1), byrow=TRUE, ncol=4)
avg_walk_speed_m_per_sec <- median(df$speed,na.rm=TRUE) # Average time
dlm_spec <-dlm(FF= f_mat,GG= g_mat,V= v_mat,W =diag(c(5, 5, 1, 1)^2),
               m0= matrix(c(coordinates[1, ],rep(avg_walk_speed_m_per_sec/dt, 2)),ncol=1),
               C0= diag(rep(10^2, 4)))
dlm_filter_mod <-dlmFilter(coordinates(spat_df), dlm_spec)
dlm_smooth_mod <-dlmSmooth(dlm_filter_mod)
```

Below are the full raw data points, Kalman filter estimates, and Kalman smoother estimates.

```{r}
plot(cbind(coordinates(spat_df)[1:nrow(coordinates(spat_df)), ], dlm_filter_mod$m[2:nrow(dlm_filter_mod$m), 1:2], dlm_smooth_mod$s[2:nrow(dlm_smooth_mod$s),1:2]),
     type='p', col =c("black", "red", "blue"), xlab="UTM X", ylab="UTM Y")
legend("topright", col =c("black", "red", "blue"),pch = 1, 
       legend =c("raw", "kalman filter","kalman smoother"))
```

To get a clearer view, we plot the first 100 observations of each:

```{r}
plot(cbind(coordinates(spat_df)[1:100,], dlm_filter_mod$m[2:101, 1:2], dlm_smooth_mod$s[2:101,1:2]),
     type='p', col =c("black", "red", "blue"), xlab="UTM X", ylab="UTM Y")
legend("topright", col =c("black", "red", "blue"),pch = 1, 
       legend =c("raw", "kalman filter","kalman smoother"))
```

To calculate speed, we use the following equation:

```{r}
speed <- sqrt(dlm_smooth_mod$s[, 3]^2+dlm_smooth_mod$s[, 4]^2)
```

```{r}
time$kalman_speed <- speed[2:length(speed)]
ggplot(time) + 
  geom_point(aes(x=temperature,y=kalman_speed)) +
  geom_smooth(aes(x=temperature,y=kalman_speed),method='lm')
summary(lm(data=time,kalman_speed~temperature))
```

After removing unwanted data points and modeling the data using a "Kalman filter" to calculate our own speed values, we observe the opposite trend: that each increase in Farenheit is associated with a 0.01 unit *increase* in speed -- possibly indicating Wayne hurrying along when it's getting hotter.

# Model Selection

Before beginning to select a model, we must narrow our data to only those data points after the first 5 minutes of Wayne's travel:

```{r}
df$longitude <- spat_df@coords[,1]
df$latitude <- spat_df@coords[,2]
new_df <- data.frame()
for (i in split(df,df$day)) {
  for (j in 1:nrow(i)) {
    if (i$time[j] > i[1,]$time + 300) { # First 5 minutes
      new_df <- rbind(new_df,i[j,])
    }
  }
}
df <- new_df
```

This portion of the report will focus on selecting a model to predict values for Wayne's trips. It will predict three values necessary to plant a bomb: time, longitude, and latitude. 

As predicting based on Kalman filter alone (dlm::dlmForecast) produced extremely biased predictions, I narrowed my model choices down to two basic forms: OLS regression (which assumes a linear relationship between variables, and attempts to minimize squared errors), and a generalized additive model (GAM), which is a generalized linear model that "smooths," or transforms, variables by applying a function to them. I begin by creating both models to explain longitude data (given latitude and time):

```{r}
ols_long <- lm(data=df,longitude~latitude+time) # OLS
ols_long_preds <- predict(ols_long)
ols_long_resids <- df$longitude - ols_long_preds

gam_long <- mgcv::gam(longitude~s(latitude)+s(time_long),data=df) # GAM
gam_long_preds <- predict(gam_long)
gam_long_resids <- df$longitude - gam_long_preds

par(mfrow=c(1,2))
plot(ols_long_preds,ols_long_resids)
plot(gam_long_preds,gam_long_resids)
```

The OLS model (left) produces small errors at certain points, but wildly inaccurate guesses at other points. The GAM model (right) applies "smoothing" to latitude and time data, and thus creates a lot of data with modest amounts of error. While both models have some degree of accuracy, I end up choosing the GAM model because its errors appear to be consistently smaller:

```{r}
summary(ols_long_resids); summary(gam_long_resids)
```

The following code applies OLS and GAM models to the other variables -- latitude and time elapsed. 

```{r}
ols_lat <- lm(data=df,latitude~longitude+time) # OLS
ols_lat_preds <- predict(ols_lat)
ols_lat_resids <- df$latitude - ols_lat_preds

gam_lat<- mgcv::gam(latitude~s(longitude)+s(time_long),data=df) # GAM
gam_lat_preds <- predict(gam_lat)
gam_lat_resids <- df$latitude - gam_lat_preds

par(mfrow=c(1,2))
plot(ols_lat_preds,ols_lat_resids)
plot(gam_lat_preds,gam_lat_resids)

summary(ols_lat_resids); summary(gam_lat_resids)
```

```{r}
ols_time <- lm(data=df,time_long~longitude+latitude) # OLS
ols_time_preds <- predict(ols_time)
ols_time_resids <- df$time_long - ols_time_preds

gam_time <- mgcv::gam(time_long~s(longitude)+s(latitude),data=df) # GAM
gam_time_preds <- predict(gam_time)
gam_time_resids <- df$time_long - gam_time_preds

par(mfrow=c(1,2))
plot(ols_time_preds,ols_time_resids)
plot(gam_time_preds,gam_time_resids)

summary(ols_time_resids); summary(gam_time_resids)
```

Having created prediction algorithms, to select bomb locations, I choose the place where the prediction's error for longitude and latitude (their summed absolute value) is smallest. The prediction ends up performing best on 8/24 at 23:14:17, with a combined error of only 2.22 for UTM longitude and latitude. However, for this particular data, 7 days after 8/24 would correspond to 8/31, which isn't part of Week 3 -- so for Bomb 1 we'll choose the next best predicted value.

```{r}
errors <- bind_cols(long=as.vector(gam_long_resids),lat=as.vector(gam_lat_resids))

errors$comb <- abs(errors$long)+abs(errors$lat)

#which(errors$comb==min(errors$comb))
#df[1862,]
#errors[1862,]

#which(errors$comb==sort(errors$comb)[2])
#df[3255,]
#errors[3255,]

#which(errors$comb==sort(errors$comb)[3])
#df[3330,]
#errors[3330,]
```

# Bomb 1:

```{r}
paste("Longitude:",gam_long_preds[which(errors$comb==sort(errors$comb)[2])])
paste("Latitude:",gam_lat_preds[which(errors$comb==sort(errors$comb)[2])])
paste("UNIX Time:",(86400*7)+gam_time_preds[which(errors$comb==sort(errors$comb)[2])])
plot(df$longitude,df$latitude)
points(gam_long_preds[which(errors$comb==sort(errors$comb)[2])],
       gam_lat_preds[which(errors$comb==sort(errors$comb)[2])],cex=5,pch=4,col='red')
```

```{r}
bomb1 <- df[which(errors$comb==sort(errors$comb)[2]),] %>% mutate(time = time+(86400*7)) 
# Add constant to make this data point 7 days later.
bomb1
plot(df$longitude,df$latitude)
points(df[which(errors$comb==sort(errors$comb)[2]),]$longitude,
       df[which(errors$comb==sort(errors$comb)[2]),]$latitude,col='red',cex=5,pch=4)
```

For the data already given, Bomb 1 would be placed on 8/26 at the above UTM coordinates. Given we're predicting for Week 3, I add 7 days to the timestamp and we arrive at **9/2/20 at the above UTM coordinates.**

# Bomb 2: 

```{r}
bomb2 <- df[which(errors$comb==sort(errors$comb)[3]),] %>% mutate(time = time+(86400*7))
# Add constant to make this data point 7 days later.
bomb2
plot(df$longitude,df$latitude)
points(df[which(errors$comb==sort(errors$comb)[3]),]$longitude,
       df[which(errors$comb==sort(errors$comb)[3]),]$latitude,col='red',cex=5,pch=4)
```

For the data already given, Bomb 2 would be placed on 8/27 at the above UTM coordinates. Given we're predicting for Week 3, I add 7 days to the timestamp and we arrive at **9/3/20 at the above UTM coordinates.**

# Model Using Week 3 Initial Points

The data below imports files from the "test_gps" folder containing initial data points for each day in Week 3, and generates new predictions for bomb locations given additional information added to the GAM model.

```{r}
df <- data.frame()
for (i in list.files("test_gps")) { 
  setwd("~/inh2102_project2/test_gps")
  dat <- read_json(i,flatten=TRUE)
  time <- c()
  time_long <- c()
  accuracy <- c()
  altitude <- c()
  bearing <- c()
  speed <- c()
  longitude <- c()
  latitude <- c()
  for (i in dat[['features']]) {
    time <- c(time,i$properties[1])
    time_long <- c(time_long,i$properties[3])
    accuracy <- c(accuracy,i$properties[4])
    altitude <- c(altitude,i$properties[5])
    bearing <- c(bearing,i$properties[6])
    speed <- c(speed,i$properties[7])
    longitude <- c(longitude,i$geometry[[2]][1])
    latitude <- c(latitude,i$geometry[[2]][2])
  }
  altitude[sapply(altitude, is.null)] <- NA
  bearing[sapply(bearing, is.null)] <- NA
  speed[sapply(speed, is.null)] <- NA
  
  df <- bind_rows(df,tibble(time=unlist(time),time_long=unlist(time_long),
                  accuracy=unlist(accuracy),altitude=unlist(altitude),
                  bearing=unlist(bearing),
                speed=unlist(speed),longitude=unlist(longitude),
               latitude=unlist(latitude))) %>% tibble()
}
```

```{r}
df$time <- paste0(substr(df$time,1,10)," ",substr(df$time,12,23))
df$time <- as.POSIXct(df$time, "%Y-%m-%d %H:%M:%S",tz="GMT")
df$day <- lubridate::day(df$time)
df$hour <- lubridate::hour(df$time)

spat_df <- SpatialPointsDataFrame(coords = df[, c("longitude", "latitude")],
                             data = df["time"],
                             proj4string=CRS("+proj=longlat +datum=WGS84")) 
spat_df@data <- spat_df@data %>% 
  mutate(time_long=df$time_long,accuracy=df$accuracy,altitude=df$altitude,
         bearing=df$bearing,speed=df$speed,day=df$day,hour=df$hour) %>%
  mutate(longitude=spat_df@coords[,1],latitude=spat_df@coords[,2])
spat_df <- spTransform(spat_df,CRSobj = "+proj=utm +zone=12 +datum=WGS84")
df$longitude <- coordinates(spat_df)[,1]
df$latitude <- coordinates(spat_df)[,2]
```

```{r}
errors <- bind_cols(long=as.vector(init_long_resids),lat=as.vector(init_lat_resids))

errors$comb <- abs(errors$long)+abs(errors$lat)
```

# Bomb 1:

```{r}
bomb1 <- df[which(errors$comb==min(errors$comb)),] 
bomb1
plot(df$longitude,df$latitude)
points(df[which(errors$comb==sort(errors$comb)[2]),]$longitude,
       df[which(errors$comb==sort(errors$comb)[2]),]$latitude,col='red',cex=5,pch=4)
```

# Bomb 2: 

```{r}
bomb2 <- df[which(errors$comb==sort(errors$comb)[2]),]
bomb2
```

The following function 

```{r}
make_pred <- function(folder_name) {
  setwd(paste0("~/inh2102_project2/"))
  df <- data.frame()
for (i in list.files(folder_name)) { 
  setwd(paste0("~/inh2102_project2/",folder_name)) 
  dat <- read_json(i,flatten=TRUE)
  time <- c()
  time_long <- c()
  accuracy <- c()
  altitude <- c()
  bearing <- c()
  speed <- c()
  longitude <- c()
  latitude <- c()
  for (i in dat[['features']]) {
    time <- c(time,i$properties[1])
    time_long <- c(time_long,i$properties[3])
    accuracy <- c(accuracy,i$properties[4])
    altitude <- c(altitude,i$properties[5])
    bearing <- c(bearing,i$properties[6])
    speed <- c(speed,i$properties[7])
    longitude <- c(longitude,i$geometry[[2]][1])
    latitude <- c(latitude,i$geometry[[2]][2])
  }
  altitude[sapply(altitude, is.null)] <- NA
  bearing[sapply(bearing, is.null)] <- NA
  speed[sapply(speed, is.null)] <- NA
  
  df <- bind_rows(df,tibble(time=unlist(time),time_long=unlist(time_long),
                  accuracy=unlist(accuracy),altitude=unlist(altitude),
                  bearing=unlist(bearing),
                speed=unlist(speed),longitude=unlist(longitude),
               latitude=unlist(latitude))) %>% tibble()
}
df$time <- paste0(substr(df$time,1,10)," ",substr(df$time,12,23))
df$time <- as.POSIXct(df$time, "%Y-%m-%d %H:%M:%S",tz="GMT")
df$day <- lubridate::day(df$time)
df$hour <- lubridate::hour(df$time)

spat_df <- SpatialPointsDataFrame(coords = df[, c("longitude", "latitude")],
                             data = df["time"],
                             proj4string=CRS("+proj=longlat +datum=WGS84")) 
spat_df@data <- spat_df@data %>% 
  mutate(time_long=df$time_long,accuracy=df$accuracy,altitude=df$altitude,
         bearing=df$bearing,speed=df$speed,day=df$day,hour=df$hour) %>%
  mutate(longitude=spat_df@coords[,1],latitude=spat_df@coords[,2])
spat_df <- spTransform(spat_df,CRSobj = "+proj=utm +zone=12 +datum=WGS84")
df$longitude <- coordinates(spat_df)[,1]
df$latitude <- coordinates(spat_df)[,2]
diff_df <- df %>% arrange(-desc(time))
diff <- c()
for (i in 1:length(df$time)) {
  diff[i] = difftime(df$time[i], df$time[i-1], units="secs")
}
diff <- diff[!is.na(diff)]
session_indices <- which(diff>=120)
spat_df$diff[2:nrow(spat_df)] <- diff
gam_long <- mgcv::gam(longitude~s(latitude)+s(time_long),data=df) # GAM
gam_long_preds <- predict(gam_long)
gam_long_resids <- df$longitude - gam_long_preds
gam_lat<- mgcv::gam(latitude~s(longitude)+s(time_long),data=df) # GAM
gam_lat_preds <- predict(gam_lat)
gam_lat_resids <- df$latitude - gam_lat_preds
gam_time <- mgcv::gam(time_long~s(longitude)+s(latitude),data=df) # GAM
gam_time_preds <- predict(gam_time)
gam_time_resids <- df$time_long - gam_time_preds
errors <- bind_cols(long=as.vector(gam_long_resids),lat=as.vector(gam_lat_resids))
errors$comb <- abs(errors$long)+abs(errors$lat)
bomb1 <- df[which(errors$comb==min(errors$comb)),] 
bomb2 <- df[which(errors$comb==sort(errors$comb)[2]),]
return(rbind(bomb1,bomb2))
}
```